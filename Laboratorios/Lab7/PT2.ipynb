{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04be2766",
   "metadata": {},
   "source": [
    "# Laboratorio 7 - Parte 2\n",
    "\n",
    "## Integrantes\n",
    "\n",
    "- Sergio Orellana 221122\n",
    "- Rodrigo Mansilla 22611\n",
    "- Carlos Valladares 221164"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0aea96",
   "metadata": {},
   "source": [
    "## Parte 2 - Teoría\n",
    "\n",
    "### Pregunta 1\n",
    "**Imagine que usted ha sido contratado para modelar el sistema de tráfico de una gran ciudad con el fin de evaluar el impacto de un nuevo sistema de metro. ¿Por qué un modelo puramente MBA, DES o DS sería, por sí solo, insuficiente para esta tarea? Describa cómo diseñaría usted un modelo híbrido para este problema, identificando qué componente del sistema sería modelado con cada paradigma y cómo interactuarían entre sí.**\n",
    "\n",
    "Un modelo puramente MBA capturaría bien la heterogeneidad y las decisiones de los viajeros (cambio de ruta, hora de salida, adopción del metro), pero no representaría con precisión los cuellos de botella operativos ni los tiempos de servicio en estaciones y cruces. Un puramente DES modelaría con detalle las colas, recursos y flujos en andenes, tornos y semáforos, pero carecería de comportamiento adaptativo y de interacción social a nivel individual. Un puramente DS ofrecería una vista macro de stocks y flujos (adopción del metro, congestión promedio), pero sería demasiado agregado para políticas que dependen de microinteracciones y de la red vial concreta.  \n",
    "Diseño un híbrido tri-paradigma:  \n",
    "• **MBA (micro):** agentes personas y vehículos con preferencias, valor del tiempo, aprendizaje y respuesta a información en tiempo real; operadores que ajustan oferta/frecuencias.  \n",
    "• **DES (operativo):** estaciones y nodos (torniquetes, andenes, escaleras, transbordos) y cruces/semaforización como procesos con recursos y colas; cálculo de tiempos de espera, utilización y throughput por franja.  \n",
    "• **DS (macro):** bucles de realimentación para adopción del metro y demanda total, congestión promedio y elasticidades que devuelven tasas y niveles a MBA y DES.  \n",
    "**Acoplo:** MBA genera llegadas por estación/hora hacia el DES; el DES devuelve tiempos de espera y fiabilidad que modifican la utilidad percibida en MBA; el DS lee agregados (congestión, puntualidad, saturación) y actualiza tendencias de demanda que condicionan la población simulada (MBA) y la capacidad operativa (DES).\n",
    "\n",
    "### Pregunta 2\n",
    "**En el \"Patrón 1: MBA → DES\", la transición de un agente a una entidad debe ser fluida. Describa a nivel conceptual y técnico (¿qué información específica se debe transferir?) cómo se realizaría esta transición en una herramienta como AnyLogic, o de forma más abstracta, en un marco de trabajo en Python que combinara las bibliotecas Mesa (para MBA) y SimPy (para DES).**\n",
    "\n",
    "Conceptualmente, cuando un agente “entra al proceso” (por ejemplo, llega a la estación), debo materializarlo como entidad de DES con los atributos mínimos para cola y servicio.  \n",
    "Datos que transfiero: id del agente y hora de llegada (para medir espera), tipo de servicio requerido, prioridad, distribución/estimación de tiempo de servicio, ubicación/estación y ruta de proceso, además de estado relevante (p. ej., tolerancia a esperar o probabilidad de abandono).  \n",
    "En un stack Mesa+SimPy, el agente crea un mensaje/objeto con esos campos y lo encola en una Store o pasa a un proceso (`env.process(servicio(entidad))`) que hace seize/hold/release sobre `Resource` o `PriorityResource`. Al terminar, el DES emite un evento de salida con tiempos de espera y servicio y el resultado (éxito/abandono) para que el agente en Mesa actualice su estado y decida su siguiente acción. En AnyLogic, mapearía propiedades del agente a atributos de la entidad al entrar a la cadena de bloques de proceso y sincronizaría de vuelta al abandonar el flujo.\n",
    "\n",
    "### Pregunta 3\n",
    "**El \"Patrón 3: DS dentro de un Agente\" es un claro ejemplo de modelado multi-escala. Proponga usted otro escenario (fuera del ámbito biológico), por ejemplo, en economía o sociología, donde este patrón sería de gran utilidad. ¿Qué representaría el agente (MBA) y qué dinámica capturaría su modelo de Dinámica de Sistemas (DS) interno?**\n",
    "\n",
    "Planteo un mercado minorista con agentes‑empresa (tiendas). Cada tienda es un agente que compite por demanda local y decide precios/promociones, pero dentro lleva un modelo DS de inventario–pedidos–backlog (stocks: inventario disponible, pedidos en tránsito y cartera; flujos: ventas, reposición y devoluciones). Ese DS interno capta retrasos y bucles (stock bajo → más pedidos → posible sobrestock al arribar) que explican roturas de stock y efecto látigo. El MBA coordina la competencia espacial y la interacción con clientes heterogéneos; el DS interno gobierna la política de reposición y la dinámica operativa de cada tienda.\n",
    "\n",
    "### Pregunta 4\n",
    "**La combinación de paradigmas de modelado presenta desafíos significativos. Desde su perspectiva, ¿cuáles cree usted que son los dos mayores desafíos al construir y validar un modelo híbrido? Considere aspectos como la calibración de parámetros entre los diferentes componentes, la complejidad del software y la validación de los resultados emergentes.**\n",
    "\n",
    "Primero, la calibración y consistencia entre escalas/paradigmas: debo alinear tasas y tiempos del DES (distribuciones de servicio y llegada), reglas del MBA (preferencias, elasticidades, aprendizaje) y parámetros del DS (ganancias de bucle, retardos) para describir la misma realidad, traduciendo métricas observables (esperas, utilización) en utilidades/comportamientos y evitando doble contabilidad de efectos. Segundo, la complejidad e inferencia sobre fenómenos emergentes: debo validar no solo series agregadas, sino patrones emergentes (distribución de viajes, formación y disipación de colas, adopción del metro), con sensibilidad y escenarios para garantizar robustez, además de verificación y pruebas de rendimiento del software.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc924fae",
   "metadata": {},
   "source": [
    "# Referencias\n",
    "\n",
    "- GeeksforGeeks. (2020, November 19). Basics of Discrete Event Simulation using SimPy. GeeksforGeeks. https://www.geeksforgeeks.org/python/basics-of-discrete-event-simulation-using-simpy/ \n",
    "- GeeksforGeeks. (2024, May 27). Queuing theory. GeeksforGeeks. https://www.geeksforgeeks.org/maths/queuing-theory/ \n",
    "- GeeksforGeeks. (2025a, July 23). Agent based modelling. GeeksforGeeks. https://www.geeksforgeeks.org/artificial-intelligence/agent-based-modelling/ \n",
    "- GeeksforGeeks. (2025b, July 23). How to do Mathematical Modeling in Python? GeeksforGeeks. https://www.geeksforgeeks.org/python/how-to-do-mathematical-modeling-in-python/ \n",
    "- GeeksforGeeks. (2025c, July 23). What is Systems Thinking? | Working, Benefits and Limitations. GeeksforGeeks. https://www.geeksforgeeks.org/software-engineering/what-is-systems-thinking-working-benefits-and-limitations/ \n",
    "- GeeksforGeeks. (2025d, August 14). Agents in AI. GeeksforGeeks. https://www.geeksforgeeks.org/artificial-intelligence/agents-artificial-intelligence/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65e2a94",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Práctica: Modelo Híbrido (MBA + DS + DES)\n",
    "\n",
    "### Descripción del Modelo\n",
    "\n",
    "Este modelo integra tres paradigmas:\n",
    "- **MBA (Agent-Based Model)**: Agentes que se mueven e interactúan en el espacio\n",
    "- **DS (System Dynamics)**: Cada agente tiene un stock de energía con flujos de entrada/salida\n",
    "- **DES (Discrete Event Simulation)**: Estación de recarga como recurso limitado con colas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d254f2",
   "metadata": {},
   "source": [
    "### 1. Importar Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d12f8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import simpy\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51182964",
   "metadata": {},
   "source": [
    "### 2. Definir Parámetros del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bdeacee",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_AGENTES = 20\n",
    "ANCHO_MUNDO = 100.0\n",
    "ALTO_MUNDO = 100.0\n",
    "\n",
    "TASA_RECUPERACION_NATURAL = 0.1     \n",
    "GASTO_POR_MOVIMIENTO = 0.05          \n",
    "EFECTO_INTERACCION = 0.2             \n",
    "\n",
    "NUM_PUESTOS_RECARGA = 5             \n",
    "ENERGIA_CRITICA = 2.0               \n",
    "TIEMPO_RECARGA = 10.0               \n",
    "ENERGIA_MAXIMA = 10.0               \n",
    "TIEMPO_SIMULACION = 200.0            \n",
    "DT = 1.0                             \n",
    "\n",
    "RADIO_INTERACCION = 5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5077cfc5",
   "metadata": {},
   "source": [
    "### 3. Clase Agente (Integración MBA + DS + DES)\n",
    "\n",
    "Esta clase integra los tres paradigmas:\n",
    "- **Atributos MBA**: posición, velocidad\n",
    "- **Atributos DS**: energía (stock), tasas de flujo\n",
    "- **Métodos DES**: proceso de recarga con recursos limitados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce43ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agente:\n",
    "    def __init__(self, id_agente, posicion_inicial, env, estacion_recarga):\n",
    "\n",
    "        self.id = id_agente\n",
    "        \n",
    "        self.posicion = np.array(posicion_inicial, dtype=float)\n",
    "        angulo = random.uniform(0, 2 * np.pi)\n",
    "        velocidad_magnitud = random.uniform(0.5, 2.0)\n",
    "        self.velocidad = np.array([\n",
    "            velocidad_magnitud * np.cos(angulo),\n",
    "            velocidad_magnitud * np.sin(angulo)\n",
    "        ])\n",
    "        \n",
    "        self.energia = ENERGIA_MAXIMA  \n",
    "\n",
    "        self.env = env\n",
    "        self.estacion_recarga = estacion_recarga\n",
    "        self.en_recarga = False  \n",
    "        \n",
    "        self.veces_recargado = 0\n",
    "        self.tiempo_total_esperando = 0.0\n",
    "    \n",
    "    def proceso_recarga(self):\n",
    "        \n",
    "        if self.en_recarga:\n",
    "            return  \n",
    "        \n",
    "        self.en_recarga = True\n",
    "        tiempo_inicio_espera = self.env.now\n",
    "        \n",
    "        print(f\"  [DES] Agente {self.id} solicita recarga en t={self.env.now:.1f} (energía={self.energia:.2f})\")\n",
    "        \n",
    "        with self.estacion_recarga.request() as req:\n",
    "            yield req  \n",
    "            \n",
    "            tiempo_espera = self.env.now - tiempo_inicio_espera\n",
    "            self.tiempo_total_esperando += tiempo_espera\n",
    "            \n",
    "            print(f\"  [DES] Agente {self.id} inicia recarga en t={self.env.now:.1f} (esperó {tiempo_espera:.1f} min)\")\n",
    "            \n",
    "            yield self.env.timeout(TIEMPO_RECARGA)\n",
    "            \n",
    "            self.energia = ENERGIA_MAXIMA\n",
    "            self.veces_recargado += 1\n",
    "            \n",
    "            print(f\"  [DES] Agente {self.id} termina recarga en t={self.env.now:.1f} (energía={self.energia:.2f})\")\n",
    "        \n",
    "        self.en_recarga = False\n",
    "    \n",
    "    def actualizar_estado(self, efecto_interaccion_neto, dt):\n",
    "      \n",
    "        recuperacion = TASA_RECUPERACION_NATURAL * dt\n",
    "        \n",
    "        velocidad_magnitud = np.linalg.norm(self.velocidad)\n",
    "        gasto_movimiento = GASTO_POR_MOVIMIENTO * velocidad_magnitud * dt\n",
    "        \n",
    "        efecto_interacciones = efecto_interaccion_neto * dt\n",
    "        \n",
    "        self.energia += recuperacion - gasto_movimiento + efecto_interacciones\n",
    "        \n",
    "        self.energia = min(self.energia, ENERGIA_MAXIMA)\n",
    "        \n",
    "\n",
    "        self.posicion += self.velocidad * dt\n",
    "        \n",
    "        if self.posicion[0] <= 0 or self.posicion[0] >= ANCHO_MUNDO:\n",
    "            self.velocidad[0] = -self.velocidad[0]\n",
    "            self.posicion[0] = np.clip(self.posicion[0], 0, ANCHO_MUNDO)\n",
    "        \n",
    "        if self.posicion[1] <= 0 or self.posicion[1] >= ALTO_MUNDO:\n",
    "            self.velocidad[1] = -self.velocidad[1]\n",
    "            self.posicion[1] = np.clip(self.posicion[1], 0, ALTO_MUNDO)\n",
    "        \n",
    "        if self.energia < ENERGIA_CRITICA and not self.en_recarga:\n",
    "            self.env.process(self.proceso_recarga())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f1ef41",
   "metadata": {},
   "source": [
    "### 4. Función Principal de Simulación\n",
    "\n",
    "Esta función orquesta el bucle principal que integra:\n",
    "1. **MBA**: Detección de interacciones entre agentes cercanos\n",
    "2. **DS**: Actualización de stocks de energía\n",
    "3. **DES**: Gestión de eventos de recarga\n",
    "4. **Recolección de datos** para análisis posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f1b769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ejecutar_simulacion(env, agentes, tiempo_simulacion):\n",
    "\n",
    "    historial_energia = []\n",
    "    historial_agentes_en_cola = []\n",
    "    historial_tiempo = []\n",
    "    \n",
    " \n",
    "    print(f\"Agentes: {len(agentes)}\")\n",
    "    print(f\"Puestos de recarga: {NUM_PUESTOS_RECARGA}\")\n",
    "    print(f\"Duración: {tiempo_simulacion} unidades de tiempo\")\n",
    "\n",
    "    \n",
    "    while env.now < tiempo_simulacion:\n",
    "        tiempo_actual = env.now\n",
    "        \n",
    "        efectos_interaccion = defaultdict(float)\n",
    "        \n",
    "        for i, agente_i in enumerate(agentes):\n",
    "            for j, agente_j in enumerate(agentes):\n",
    "                if i >= j:  \n",
    "                    continue\n",
    "                \n",
    "                distancia = np.linalg.norm(agente_i.posicion - agente_j.posicion)\n",
    "                \n",
    "                if distancia < RADIO_INTERACCION:\n",
    "                    efecto = random.choice([-1, 1]) * EFECTO_INTERACCION\n",
    "                    \n",
    "                    efectos_interaccion[agente_i.id] += efecto\n",
    "                    efectos_interaccion[agente_j.id] += efecto\n",
    "        \n",
    "        for agente in agentes:\n",
    "            efecto_neto = efectos_interaccion.get(agente.id, 0.0)\n",
    "            agente.actualizar_estado(efecto_neto, DT)\n",
    "        \n",
    "\n",
    "        energia_promedio = np.mean([a.energia for a in agentes])\n",
    "        historial_energia.append(energia_promedio)\n",
    "        \n",
    "        \n",
    "        agentes_en_cola = sum(1 for a in agentes if a.en_recarga)\n",
    "        historial_agentes_en_cola.append(agentes_en_cola)\n",
    "        \n",
    "        historial_tiempo.append(tiempo_actual)\n",
    "        \n",
    "        if int(tiempo_actual) % 20 == 0 and tiempo_actual > 0:\n",
    "            energia_min = min(a.energia for a in agentes)\n",
    "            energia_max = max(a.energia for a in agentes)\n",
    "            print(f\"t={tiempo_actual:.0f}: Energía promedio={energia_promedio:.2f}, \"\n",
    "                  f\"Min={energia_min:.2f}, Max={energia_max:.2f}, \"\n",
    "                  f\"En recarga={agentes_en_cola}\")\n",
    "        \n",
    "        yield env.timeout(DT)\n",
    "    \n",
    "\n",
    "    \n",
    "    return {\n",
    "        'tiempo': historial_tiempo,\n",
    "        'energia_promedio': historial_energia,\n",
    "        'agentes_en_cola': historial_agentes_en_cola,\n",
    "        'agentes': agentes\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a83b5b",
   "metadata": {},
   "source": [
    "### 5. Configuración y Ejecución - Experimento 1\n",
    "\n",
    "**Configuración**: NUM_PUESTOS_RECARGA = 5 (capacidad generosa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e44633a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agentes: 20\n",
      "Puestos de recarga: 5\n",
      "Duración: 200.0 unidades de tiempo\n",
      "t=20: Energía promedio=9.86, Min=9.03, Max=10.00, En recarga=0\n",
      "t=40: Energía promedio=9.69, Min=7.59, Max=10.00, En recarga=0\n",
      "t=60: Energía promedio=9.70, Min=7.55, Max=10.00, En recarga=0\n",
      "t=80: Energía promedio=9.72, Min=7.97, Max=10.00, En recarga=0\n",
      "t=100: Energía promedio=9.71, Min=8.08, Max=10.00, En recarga=0\n",
      "t=120: Energía promedio=9.70, Min=6.81, Max=10.00, En recarga=0\n",
      "t=140: Energía promedio=9.71, Min=6.96, Max=10.00, En recarga=0\n",
      "t=160: Energía promedio=9.74, Min=7.12, Max=10.00, En recarga=0\n",
      "t=180: Energía promedio=9.74, Min=8.07, Max=10.00, En recarga=0\n"
     ]
    }
   ],
   "source": [
    "NUM_PUESTOS_RECARGA = 5\n",
    "\n",
    "env = simpy.Environment()\n",
    "\n",
    "estacion_recarga = simpy.Resource(env, capacity=NUM_PUESTOS_RECARGA)\n",
    "\n",
    "agentes = []\n",
    "for i in range(NUM_AGENTES):\n",
    "    pos_inicial = [\n",
    "        random.uniform(0, ANCHO_MUNDO),\n",
    "        random.uniform(0, ALTO_MUNDO)\n",
    "    ]\n",
    "    agente = Agente(i, pos_inicial, env, estacion_recarga)\n",
    "    agentes.append(agente)\n",
    "\n",
    "resultados_exp1 = {}\n",
    "\n",
    "def simulacion_con_retorno():\n",
    "    resultado = yield env.process(ejecutar_simulacion(env, agentes, TIEMPO_SIMULACION))\n",
    "    global resultados_exp1\n",
    "    resultados_exp1 = resultado\n",
    "\n",
    "env.process(simulacion_con_retorno())\n",
    "env.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935fe14f",
   "metadata": {},
   "source": [
    "### 6. Análisis de Resultados - Experimento 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c98c01da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Uso de la Estación de Recarga:\n",
      "   • Total de recargas realizadas: 0\n",
      "   • Agentes que usaron la estación: 0/20\n",
      "   • Promedio de recargas por agente: 0.00\n",
      "\n",
      " Estado Final de Energía:\n",
      "   • Energía promedio: 9.75\n",
      "   • Energía mínima: 8.22\n",
      "   • Energía máxima: 10.00\n"
     ]
    }
   ],
   "source": [
    "if resultados_exp1:\n",
    "\n",
    "    \n",
    "    total_recargas = sum(a.veces_recargado for a in agentes)\n",
    "    agentes_que_recargaron = sum(1 for a in agentes if a.veces_recargado > 0)\n",
    "    \n",
    "    print(f\"\\n Uso de la Estación de Recarga:\")\n",
    "    print(f\"   • Total de recargas realizadas: {total_recargas}\")\n",
    "    print(f\"   • Agentes que usaron la estación: {agentes_que_recargaron}/{NUM_AGENTES}\")\n",
    "    print(f\"   • Promedio de recargas por agente: {total_recargas/NUM_AGENTES:.2f}\")\n",
    "    \n",
    "    if agentes_que_recargaron > 0:\n",
    "        tiempo_espera_promedio = sum(a.tiempo_total_esperando for a in agentes) / agentes_que_recargaron\n",
    "        print(f\"   • Tiempo promedio de espera en cola: {tiempo_espera_promedio:.2f} unidades\")\n",
    "    \n",
    "    # Análisis de energía\n",
    "    energia_final_promedio = np.mean([a.energia for a in agentes])\n",
    "    energia_final_min = min(a.energia for a in agentes)\n",
    "    energia_final_max = max(a.energia for a in agentes)\n",
    "    \n",
    "    print(f\"\\n Estado Final de Energía:\")\n",
    "    print(f\"   • Energía promedio: {energia_final_promedio:.2f}\")\n",
    "    print(f\"   • Energía mínima: {energia_final_min:.2f}\")\n",
    "    print(f\"   • Energía máxima: {energia_final_max:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80e6638",
   "metadata": {},
   "source": [
    "\n",
    "### 8. Experimento 2: Cuello de Botella\n",
    "\n",
    "**Configuración**: NUM_PUESTOS_RECARGA = 1 (capacidad limitada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f19d234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agentes: 20\n",
      "Puestos de recarga: 1\n",
      "Duración: 200.0 unidades de tiempo\n",
      "t=20: Energía promedio=9.88, Min=9.07, Max=10.00, En recarga=0\n",
      "t=40: Energía promedio=9.95, Min=9.16, Max=10.00, En recarga=0\n",
      "t=60: Energía promedio=9.97, Min=9.46, Max=10.00, En recarga=0\n",
      "t=80: Energía promedio=9.87, Min=9.33, Max=10.00, En recarga=0\n",
      "t=100: Energía promedio=9.92, Min=9.51, Max=10.00, En recarga=0\n",
      "t=120: Energía promedio=9.95, Min=9.47, Max=10.00, En recarga=0\n",
      "t=140: Energía promedio=9.95, Min=9.60, Max=10.00, En recarga=0\n",
      "t=160: Energía promedio=9.90, Min=9.04, Max=10.00, En recarga=0\n",
      "t=180: Energía promedio=9.93, Min=9.54, Max=10.00, En recarga=0\n"
     ]
    }
   ],
   "source": [
    "NUM_PUESTOS_RECARGA = 1 \n",
    "\n",
    "env2 = simpy.Environment()\n",
    "\n",
    "estacion_recarga2 = simpy.Resource(env2, capacity=NUM_PUESTOS_RECARGA)\n",
    "\n",
    "agentes2 = []\n",
    "for i in range(NUM_AGENTES):\n",
    "    pos_inicial = [\n",
    "        random.uniform(0, ANCHO_MUNDO),\n",
    "        random.uniform(0, ALTO_MUNDO)\n",
    "    ]\n",
    "    agente = Agente(i, pos_inicial, env2, estacion_recarga2)\n",
    "    agentes2.append(agente)\n",
    "\n",
    "resultados_exp2 = {}\n",
    "\n",
    "def simulacion_con_retorno2():\n",
    "    resultado = yield env2.process(ejecutar_simulacion(env2, agentes2, TIEMPO_SIMULACION))\n",
    "    global resultados_exp2\n",
    "    resultados_exp2 = resultado\n",
    "\n",
    "env2.process(simulacion_con_retorno2())\n",
    "env2.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9593fe",
   "metadata": {},
   "source": [
    "### 9. Análisis de Resultados - Experimento 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1cc26e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Uso de la Estación de Recarga:\n",
      "   • Total de recargas realizadas: 0\n",
      "   • Agentes que usaron la estación: 0/20\n",
      "   • Promedio de recargas por agente: 0.00\n",
      "Estado Final de Energía:\n",
      "   • Energía promedio: 9.90\n",
      "   • Energía mínima: 9.43\n",
      "   • Energía máxima: 10.00\n",
      "   • Agentes con energía baja (<3.0): 0\n"
     ]
    }
   ],
   "source": [
    "if resultados_exp2:\n",
    "    total_recargas2 = sum(a.veces_recargado for a in agentes2)\n",
    "    agentes_que_recargaron2 = sum(1 for a in agentes2 if a.veces_recargado > 0)\n",
    "    \n",
    "    print(f\"\\n Uso de la Estación de Recarga:\")\n",
    "    print(f\"   • Total de recargas realizadas: {total_recargas2}\")\n",
    "    print(f\"   • Agentes que usaron la estación: {agentes_que_recargaron2}/{NUM_AGENTES}\")\n",
    "    print(f\"   • Promedio de recargas por agente: {total_recargas2/NUM_AGENTES:.2f}\")\n",
    "    \n",
    "    energia_final_promedio2 = np.mean([a.energia for a in agentes2])\n",
    "    energia_final_min2 = min(a.energia for a in agentes2)\n",
    "    energia_final_max2 = max(a.energia for a in agentes2)\n",
    "    \n",
    "    print(f\"Estado Final de Energía:\")\n",
    "    print(f\"   • Energía promedio: {energia_final_promedio2:.2f}\")\n",
    "    print(f\"   • Energía mínima: {energia_final_min2:.2f}\")\n",
    "    print(f\"   • Energía máxima: {energia_final_max2:.2f}\")\n",
    "    \n",
    "    agentes_criticos = sum(1 for a in agentes2 if a.energia < ENERGIA_CRITICA * 1.5)\n",
    "    print(f\"   • Agentes con energía baja (<{ENERGIA_CRITICA * 1.5}): {agentes_criticos}\")\n",
    "    \n",
    "\n",
    "else:\n",
    "    print(\"No se pudieron obtener resultados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecbdf53",
   "metadata": {},
   "source": [
    "\n",
    "### Preguntas de Análisis\n",
    "\n",
    "1. **¿Cuántos agentes, en promedio, utilizan la estación durante la simulación con 5 puestos?**\n",
    "   - 0 agentes en promedio. La utilización de la estación fue **0%** sin recargas. Dado que con parámetros actuales los agentes mantienen energías cercanas al máximo, aun con 5 puestos no se activa el proceso DES.\n",
    "\n",
    "2. **¿Cómo impacta reducir a 1 puesto en la dinámica general de energía?**\n",
    "   - Sin impacto observable bajo estos parámetros. Con 1 puesto se registró:\n",
    "   - **Total de recargas:** 0  \n",
    "   - **Energía promedio final:** 9.90 (min 9.43, máx 10.00)  \n",
    "   - **Agentes con energía < 3.0:** 0  \n",
    "   La población se mantiene en un régimen no restrictivo: la energía promedio permanece alta y estable.\n",
    "\n",
    "3. **¿Qué efecto tiene el cuello de botella DES sobre el comportamiento agregado MBA+DS?**\n",
    "   - **Ninguno** en estas corridas. El supuesto cuello de botella **no se activa** (no hay demanda de recarga), por lo que la energía promedio se mantiene entre **9.87–9.97** a lo largo del tiempo y no se observan colas ni degradación de la dinámica agregada.\n",
    "\n",
    "\n",
    "4. **Describa el bucle de retroalimentación entre DES y MBA+DS**\n",
    "   - En el esquema previsto, baja energía → demanda de recarga (DES) → colas si la capacidad es insuficiente → mayor tiempo sin actividad útil → efectos sobre interacción y movimiento (MBA) → cambios en los flujos de energía (DS).  En estas simulaciones, el recuperación natural domina y el gasto por movimiento/interacción es bajo; por ello no se cruza el umbral crítico y el bucle DES↔MBA+DS permanece inactivo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab1333d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Uso de Gen AI - Documentación\n",
    "\n",
    "#### Prompt Utilizado:\n",
    "```\n",
    "Ayúdame a implementar un modelo híbrido en Python con SimPy que integre MBA, DS y DES. \n",
    "Necesito:\n",
    "\n",
    "1. Una clase Agente que tenga:\n",
    "   - Atributos MBA: posición, velocidad, movimiento en 2D\n",
    "   - Atributos DS: energía como stock con flujos (recuperación, gasto por movimiento)\n",
    "   - Métodos DES: proceso de recarga usando recursos SimPy con colas\n",
    "\n",
    "2. Función principal que:\n",
    "   - Detecte interacciones entre agentes cercanos (MBA)\n",
    "   - Actualice energía con integración de Euler (DS)\n",
    "   - Gestione eventos de recarga cuando energía < umbral crítico (DS→DES)\n",
    "   - Recolecte datos para análisis temporal\n",
    "\n",
    "3. Explica cómo se integran los tres paradigmas y dónde ocurren las transiciones\n",
    "\n",
    "Quiero entender la arquitectura del modelo híbrido, no solo el código.\n",
    "```\n",
    "\n",
    "#### ¿Por qué funcionó este prompt?\n",
    "\n",
    "1. **Especifica los tres paradigmas**: Dejé claro que necesito MBA, DS y DES integrados\n",
    "2. **Estructura clara**: Separé por componentes (clase, función, integración)\n",
    "3. **Énfasis en transiciones**: Pedí explícitamente cómo se conectan los paradigmas (DS→DES, MBA→DS)\n",
    "4. **Contexto técnico**: Mencioné SimPy, integración de Euler, recursos con colas\n",
    "5. **Objetivo de aprendizaje**: Pedí entender la arquitectura, no solo copiar código\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
